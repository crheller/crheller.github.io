<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-XDX3RFLYFH"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-XDX3RFLYFH");</script> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Lab database and compute ecosystem | Charles Heller </title> <meta name="author" content="Charles Heller"> <meta name="description" content="Full stack development of an intergrated lab database and compute system that allows users to easily log/query experimental data and provides tools for performing automated, standardized data analysis pipelines in a high performance computing environment."> <meta name="keywords" content="neuroscience, data science, max planck institute, charlie"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://crheller.github.io/projects/3_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Charles</span> Heller </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Lab database and compute ecosystem</h1> <p class="post-description">Full stack development of an intergrated lab database and compute system that allows users to easily log/query experimental data and provides tools for performing automated, standardized data analysis pipelines in a high performance computing environment.</p> </header> <article> <h2 id="introduction">Introduction</h2> <p>Reproducible, standardized data analysis pipelines are critically important in research. As the volume and size of the datasets collected grows (as is currently the case in systems neuroscience) this need becomes more apparent. In this project, I developed an internal lab database and compute ecosystem that allows experimental data to be easily logged and queried by users. It also provides the framework and tools to facilitate automated, standardized data analysis using high performance computing by all lab members.</p> <p>Our lab has developed several custom data processing pipelines that are critical for supporting our everyday research. In the past, team members were expected to run these pipelines on our local lab servers. This approach had two main drawbacks. First, due to limited internal compute resources, these pipelines could often take anywhere from three weeks to over a month to complete, per dataset. Given that we regularly collect 10-15 datasets per week, this timeline was not feasible for our research. Second, the pipelines were usually run in Jupyter notebooks using non-version controlled source code. Therefore, discrepancies between processed data were difficult to track down. With my new system, a single dataset can be processed in 2-4 days and the processing is done with standardized, version controlled source code that is shared between lab members.</p> <p>This is a large project that I have been independently developing over roughly 3 years in the <a href="https://www.rolilab.com/" rel="external nofollow noopener" target="_blank">RoLi Lab</a>. Although I am still working on incremental improvements, the system is fully operational and currently being used by all lab members. Because it lives on our institute’s private network and contains proprietary data, I am not able to go into full details or release any of the associated code or tools I have built here. Therefore, the goal of this post is to provide an overview of the system and its component parts, hopefully illustrating the advantages of building such a system and motivating others to adopt similar ecosystems for data management and analysis in their own research.</p> <h2 id="outline">Outline</h2> <ol> <li><a href="#overview">Overview</a></li> <li><a href="#mongo">Database</a></li> <li><a href="#dashboard">Web API</a></li> <li><a href="#julia">Julia API</a></li> <li><a href="#qmonitor">Automated db watchdog</a></li> <li><a href="#hpc">Max Planck High Performance Computing System</a></li> </ol> <h2 id="overview"> <a name="overview"></a>Overview</h2> <p>At a high level, the system is composed of 4 parts:</p> <ol> <li>Database backend</li> <li>Frontend database APIs</li> <li>Database watchdog to monitor database entries, send compute jobs, and collects results</li> <li>Compute environment (remote HPC system)</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/db/schematic2-480.webp 480w,/assets/img/db/schematic2-800.webp 800w,/assets/img/db/schematic2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/db/schematic2.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" title="schema" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> High level overview of the ecosystem. The database backend, web API, Julia API, and database watchdog are all hosted on our local lab server(s). The compute environment is the remote, high performance computing system of the Max Planck Institute and is maintained by the MPI core staff. </div> <p>In the following sections, I will unpack each of these components in more detail.</p> <h2 id="database"> <a name="mongo"></a>Database</h2> <p>I chose to implement the database backend using a <a href="https://en.wikipedia.org/wiki/NoSQL" rel="external nofollow noopener" target="_blank">NoSQL</a> approach. Specifically, I used <a href="https://www.mongodb.com/" rel="external nofollow noopener" target="_blank">MongoDB</a>. There were two reasons for this.</p> <ol> <li>NoSQL allows a high level of flexibility in terms of the database schema. This is useful for us, as the types of experiments that are performed in the lab will evolve over time. Thus, a system that can flexibly adapt to log new types of information was desired.</li> <li>MongoDB provides nice tools for <a href="https://www.mongodb.com/docs/manual/replication/" rel="external nofollow noopener" target="_blank">Replication</a> which ensures that even if one of our lab servers goes down, the database remains live and accessible.</li> </ol> <h4 id="database-collections">Database collections</h4> <p>The database consists of three separate <a href="https://www.mongodb.com/docs/manual/core/databases-and-collections/" rel="external nofollow noopener" target="_blank">collections</a>:</p> <ol> <li>users <ul> <li>Stores general lab member user information such as email, lab username, HPC account information, and login credentials for the <a href="#dashboard">web API</a> </li> </ul> </li> <li>data <ul> <li>Stores meta data for every experiment.</li> <li>Consists of required fields (e.g., timestamp of data acquisition and location of the data) <ul> <li>… as well as non-required fields (e.g., free text comments about the experiment)</li> </ul> </li> </ul> </li> <li>queue <ul> <li>Stores data analyses to be performed on HPC system</li> <li>Can be uniquely linked to the <code class="language-plaintext highlighter-rouge">data</code> collection via the dataset acquisition timestamp</li> </ul> </li> </ol> <h2 id="web-api"> <a name="dashboard"></a>Web API</h2> <p>In order to provide a user-friendly interface with the database, I built a lightweight web API which lives in a docker container on a lab server and was built using a combination of PHP, CSS, HTML, and JavaScript. This platform serves 3 main purposes:</p> <ol> <li>Allow users to enter new experimental data into the database</li> </ol> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-0 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/db/db_add-480.webp 480w,/assets/img/db/db_add-800.webp 800w,/assets/img/db/db_add-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/db/db_add.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="add" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ol start="2"> <li>Allow user to browse experimental data</li> </ol> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-0 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/db/db_browse-480.webp 480w,/assets/img/db/db_browse-800.webp 800w,/assets/img/db/db_browse-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/db/db_browse.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="browse" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ol start="3"> <li>Allow users to monitor HPC job status</li> </ol> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-0 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/db/db_queue1-480.webp 480w,/assets/img/db/db_queue1-800.webp 800w,/assets/img/db/db_queue1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/db/db_queue1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="browse" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-0 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/db/db_queue2-480.webp 480w,/assets/img/db/db_queue2-800.webp 800w,/assets/img/db/db_queue2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/db/db_queue2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="browse" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="julia-api"> <a name="julia"></a>Julia API</h2> <p>Our lab performs most data analysis and visualization using Julia. Therefore, I built a very simple Julia API to allow users to interact with the database from code. The two main use cases are:</p> <ol> <li>Query the database to find a set of datasets to analyze: <div class="language-julia highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">julia</span><span class="o">&gt;</span> <span class="n">dbquery</span><span class="x">([</span><span class="s">"data_raw_path"</span><span class="x">,</span> <span class="s">"runclass.id"</span><span class="x">],</span> <span class="n">filter</span><span class="o">=</span><span class="kt">Dict</span><span class="x">(</span><span class="s">"user"</span><span class="o">=&gt;</span><span class="s">"charlie"</span><span class="x">,</span> <span class="s">"runclass.id"</span><span class="o">=&gt;</span><span class="s">"ARB-diff"</span><span class="x">))</span>
<span class="mi">6</span><span class="n">×2</span> <span class="n">DataFrame</span>
 <span class="n">Row</span> <span class="n">│</span> <span class="n">data_raw_path</span>                      <span class="n">runclass</span><span class="o">.</span><span class="n">id</span> 
  <span class="n">│</span> <span class="kt">Any</span>                                <span class="kt">Any</span>         
<span class="n">─────┼────────────────────────────────────────────────</span>
<span class="mi">1</span> <span class="n">│</span> <span class="o">/</span><span class="n">nfs</span><span class="o">/</span><span class="n">data6</span><span class="o">/</span><span class="n">charlie</span><span class="o">/</span><span class="n">data_raw</span><span class="o">/</span><span class="mi">2022</span><span class="n">…</span>  <span class="n">ARB</span><span class="o">-</span><span class="n">diff</span>
<span class="mi">2</span> <span class="n">│</span> <span class="o">/</span><span class="n">nfs</span><span class="o">/</span><span class="n">data6</span><span class="o">/</span><span class="n">charlie</span><span class="o">/</span><span class="n">data_raw</span><span class="o">/</span><span class="mi">2022</span><span class="n">…</span>  <span class="n">ARB</span><span class="o">-</span><span class="n">diff</span>
<span class="mi">3</span> <span class="n">│</span> <span class="o">/</span><span class="n">nfs</span><span class="o">/</span><span class="n">data6</span><span class="o">/</span><span class="n">charlie</span><span class="o">/</span><span class="n">data_raw</span><span class="o">/</span><span class="mi">2022</span><span class="n">…</span>  <span class="n">ARB</span><span class="o">-</span><span class="n">diff</span>
<span class="mi">4</span> <span class="n">│</span> <span class="o">/</span><span class="n">nfs</span><span class="o">/</span><span class="n">data6</span><span class="o">/</span><span class="n">charlie</span><span class="o">/</span><span class="n">data_raw</span><span class="o">/</span><span class="mi">2022</span><span class="n">…</span>  <span class="n">ARB</span><span class="o">-</span><span class="n">diff</span>
<span class="mi">5</span> <span class="n">│</span> <span class="o">/</span><span class="n">nfs</span><span class="o">/</span><span class="n">data7</span><span class="o">/</span><span class="n">charlie</span><span class="o">/</span><span class="n">data_raw</span><span class="o">/</span><span class="mi">2022</span><span class="n">…</span>  <span class="n">ARB</span><span class="o">-</span><span class="n">diff</span>
<span class="mi">6</span> <span class="n">│</span> <span class="o">/</span><span class="n">nfs</span><span class="o">/</span><span class="n">data1</span><span class="o">/</span><span class="n">charlie</span><span class="o">/</span><span class="n">data_raw</span><span class="o">/</span><span class="mi">2022</span><span class="n">…</span>  <span class="n">ARB</span><span class="o">-</span><span class="n">diff</span>
</code></pre></div> </div> </li> </ol> <ol start="2"> <li>Submit batch jobs to the HPC system <div class="language-julia highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">julia</span><span class="o">&gt;</span> <span class="n">dbqueue_job</span><span class="x">(</span>
             <span class="n">dataset</span><span class="o">=</span><span class="s">"20211215_093527"</span><span class="x">,</span> 
             <span class="n">user</span><span class="o">=</span><span class="s">"charlie"</span><span class="x">,</span> 
             <span class="n">compute_cluster</span><span class="o">=</span><span class="s">"raven"</span><span class="x">,</span> 
             <span class="n">job_type</span><span class="o">=</span><span class="s">"diff_registration"</span><span class="x">,</span>
             <span class="n">data_transfer_await</span><span class="o">=</span><span class="nb">false</span><span class="x">,</span> 
             <span class="n">mpcdf</span><span class="o">=</span><span class="nb">true</span><span class="x">,</span> 
             <span class="n">datafiles</span><span class="o">=</span><span class="x">[</span><span class="s">"phase_and_reference.h5"</span><span class="x">,</span> <span class="s">"registration_preps.h5"</span><span class="x">,</span> <span class="s">"reconstruction_ref_sweep.h5"</span><span class="x">],</span>
             <span class="n">datarawfiles</span><span class="o">=</span><span class="x">[</span><span class="s">"fl_a.roli"</span><span class="x">,</span> <span class="s">"fl_b.roli"</span><span class="x">],</span>
             <span class="n">job_options</span><span class="o">=</span><span class="kt">Dict</span><span class="x">(</span><span class="s">"split_idx"</span> <span class="o">=&gt;</span> <span class="mi">1</span><span class="x">,</span> <span class="s">"num_splits"</span> <span class="o">=&gt;</span> <span class="mi">40</span><span class="x">)</span>
<span class="x">)</span>
</code></pre></div> </div> <p>The above command creates a new entry in the <code class="language-plaintext highlighter-rouge">queue</code> collection which will get scraped by the <a href="#qmonitor">db watchdog</a> system that I discuss in the next section.</p> </li> </ol> <h2 id="automated-queue-monitoring"> <a name="qmonitor"></a>Automated queue monitoring</h2> <p>Running a data analysis pipeline on a High Performance Computing (HPC) system has huge advantages in terms of speed, scalability, and reproducibility. However, getting it set up can sometimes be challenging, particularly for those without prior experience writing batch scripts or working with job scheduling systems such as <a href="https://slurm.schedmd.com/documentation.html" rel="external nofollow noopener" target="_blank">SLURM</a>. In order to run a data analysis job on an HPC system, you need to transfer your data to where it can be accessed by the compute nodes, build a “batch script” (the set of instructions that tells the machine what to do with the data), submit this batch script to SLURM, and you need to locate the output of your job and move it back to a local server.</p> <p>To streamline this process for standard data pipelines in our lab, I built an automated system that allows users to easily utilize our institute’s HPC system. As a result of this automation, from the perspective of the user, all that needs to be done to submit a job is run one line of code in <a href="#julia">Julia</a>, monitor the job’s status on the <a href="#dashboard">web API</a>, and wait for the results to be returned to their local machine in lab.</p> <p>This automation is achieved by a set of <a href="https://en.wikipedia.org/wiki/Cron" rel="external nofollow noopener" target="_blank">CronJobs</a> running on our local lab servers. These CronJobs contain 3 steps:</p> <ol> <li>Monitor the queue collection to find new entries <ul> <li>Python script to scrape the queue collection in the lab database and look for new job entries</li> <li>When a new job is found, initiate the transfer of the data to the remote compute node using <code class="language-plaintext highlighter-rouge">rsync</code> </li> <li>After the data is transferred, transfer the job batch script to the compute node</li> <li>When a new job batch script is detected on the compute node, automatically add to SLURM queue</li> </ul> </li> <li>Monitor the status of in progress transfers <ul> <li>Python script to query the queue collection and find jobs with status = transfer in progress</li> <li>Quantify transfer progress by capturing <code class="language-plaintext highlighter-rouge">rsync --progress</code> output and adding this information to the database</li> </ul> </li> <li>Monitor the status of in progress jobs <ul> <li>Capture SLURM PID upon being added to job queue</li> <li>Monitor remote results directory for analysis output file</li> <li>When final output is detected, initiate transfer of output file(s) back to local lab server</li> </ul> </li> </ol> <p>All of these tools live in a single git repository. In order to get started using the system, users just need to clone the repo and run a short python install script which sets up the user’s cron tab, requests the user’s credentials, and mounts the remote data directory (using <code class="language-plaintext highlighter-rouge">sshfs</code>) in order to achieve automation. In addition to these automation tools, this repository also contains a folder with the lab analysis source code to be executed on the remote HPC system. This ensures that all users analyze their data using the same procedure which increases the standardization and reproducibility of data pipelines in our lab.</p> <h2 id="max-planck-high-performance-computing-system"> <a name="hpc"></a>Max Planck High Performance Computing System</h2> <p>All Max Planck Institute researchers have access to state-of-the-art HPC systems. These are managed by the <a href="https://www.mpcdf.mpg.de/" rel="external nofollow noopener" target="_blank">MPCDF</a>. Further details can be found by visiting their <a href="https://www.mpcdf.mpg.de/" rel="external nofollow noopener" target="_blank">website</a>. For the project described here, we have primarily made use of the <a href="https://www.mpcdf.mpg.de/services/supercomputing/raven" rel="external nofollow noopener" target="_blank">raven</a> compute cluster, however, my system was built to be able to utilize additional clusters and I am in the process of incporating the new <a href="https://www.mpcdf.mpg.de/services/supercomputing/viper" rel="external nofollow noopener" target="_blank">viper</a> cluster, as well.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Charles Heller. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>